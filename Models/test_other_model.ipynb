{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d4ac08",
   "metadata": {},
   "source": [
    "# üîç Test All Tuned Models on Test Data\n",
    "\n",
    "This notebook loads the three hyperparameter-tuned models (Gradient Boosting, CatBoost, AdaBoost) and evaluates them on the feature-engineered test set. All key classification metrics are computed and compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94374a7",
   "metadata": {},
   "source": [
    "## üì¶ Load Models and Test Data\n",
    "We load the three models from `../Data/interim/` and the test set from `../Data/output/feature_engineered_test_wrapper.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "558b1a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features shape: (1407, 20)\n",
      "Test target shape: (1407,)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Load models\n",
    "gbc_best = joblib.load('../Data/interim/gbc_best.pkl')\n",
    "cbc_best = joblib.load('../Data/interim/cbc_best.pkl')\n",
    "ada_best = joblib.load('../Data/interim/ada_best.pkl')\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('../Data/output/feature_engineered_test_wrapper.csv')\n",
    "X_test = test.drop(columns=['customerID', 'Churn'], errors='ignore')\n",
    "y_test = test['Churn'] if 'Churn' in test.columns else None\n",
    "if y_test is not None and (y_test.dtype == 'object' or y_test.dtype.name == 'category'):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    y_test = LabelEncoder().fit_transform(y_test)\n",
    "print(f'Test features shape: {X_test.shape}')\n",
    "if y_test is not None:\n",
    "    print(f'Test target shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65057ee",
   "metadata": {},
   "source": [
    "## üß™ Evaluate All Models\n",
    "For each model, compute Accuracy, Precision, Recall, F1-Score, and AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f38ab2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.787491</td>\n",
       "      <td>0.642586</td>\n",
       "      <td>0.451872</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.830206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.794598</td>\n",
       "      <td>0.659176</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.549142</td>\n",
       "      <td>0.832598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.781805</td>\n",
       "      <td>0.673575</td>\n",
       "      <td>0.347594</td>\n",
       "      <td>0.458554</td>\n",
       "      <td>0.827981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Accuracy  Precision    Recall  F1-Score   AUC-ROC\n",
       "0  GradientBoosting  0.787491   0.642586  0.451872  0.530612  0.830206\n",
       "1          CatBoost  0.794598   0.659176  0.470588  0.549142  0.832598\n",
       "2          AdaBoost  0.781805   0.673575  0.347594  0.458554  0.827981"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {\n",
    "    'GradientBoosting': gbc_best,\n",
    "    'CatBoost': cbc_best,\n",
    "    'AdaBoost': ada_best\n",
    "}\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else 'N/A'\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': auc\n",
    "    })\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d01fb7",
   "metadata": {},
   "source": [
    "## üìà Detailed Results Explanation & Model Selection\n",
    "The table above compares all models and ensemble techniques on the test set using key metrics:\n",
    "- **AUC-ROC**: Measures the model's ability to distinguish between churners and non-churners. Higher is better.\n",
    "- **Recall**: Measures the ability to correctly identify churners. Important for churn use cases.\n",
    "- **Accuracy, Precision, F1-Score**: Provide additional context but are less critical for imbalanced churn problems.\n",
    "\n",
    "### Which Base Model Wins?\n",
    "- Among Gradient Boosting, CatBoost, and AdaBoost, the model with the highest AUC-ROC (and, if tied, highest Recall) is considered the best base model. Check the table for the exact winner.\n",
    "- Typically, CatBoost or Gradient Boosting often perform best on tabular data, but your results may vary.\n",
    "\n",
    "### Why Use Ensemble Methods?\n",
    "- Ensemble methods (Soft Voting, Hard Voting, Stacking) combine the strengths of multiple models to improve robustness and generalization.\n",
    "- They can outperform individual models, especially if the base models make different types of errors.\n",
    "- Soft Voting averages predicted probabilities, Hard Voting uses majority class, and Stacking learns how to best combine model outputs.\n",
    "\n",
    "### Does the Ensemble Perform Better?\n",
    "- Compare the ensemble rows in the table to the best base model. If the ensemble's AUC-ROC and Recall are higher, it is the best choice for deployment.\n",
    "- If not, stick with the best individual model.\n",
    "\n",
    "**Summary:**\n",
    "- The best model for deployment is the one with the highest AUC-ROC and Recall. If an ensemble method outperforms all base models, it is preferred for its improved stability and predictive power. Otherwise, use the top-performing base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17eea4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ensemble model saved as ../Data/interim/ensemble_soft_voting.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.787491</td>\n",
       "      <td>0.642586</td>\n",
       "      <td>0.451872</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.830206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.794598</td>\n",
       "      <td>0.659176</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.549142</td>\n",
       "      <td>0.832598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.781805</td>\n",
       "      <td>0.673575</td>\n",
       "      <td>0.347594</td>\n",
       "      <td>0.458554</td>\n",
       "      <td>0.827981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ensemble (Soft Voting)</td>\n",
       "      <td>0.842217</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.542781</td>\n",
       "      <td>0.646497</td>\n",
       "      <td>0.903182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision    Recall  F1-Score   AUC-ROC\n",
       "0        GradientBoosting  0.787491   0.642586  0.451872  0.530612  0.830206\n",
       "1                CatBoost  0.794598   0.659176  0.470588  0.549142  0.832598\n",
       "2                AdaBoost  0.781805   0.673575  0.347594  0.458554  0.827981\n",
       "3  Ensemble (Soft Voting)  0.842217   0.799213  0.542781  0.646497  0.903182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stacking ensemble model saved as ../Data/interim/ensemble_stacking.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.787491</td>\n",
       "      <td>0.642586</td>\n",
       "      <td>0.451872</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.830206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.794598</td>\n",
       "      <td>0.659176</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.549142</td>\n",
       "      <td>0.832598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.781805</td>\n",
       "      <td>0.673575</td>\n",
       "      <td>0.347594</td>\n",
       "      <td>0.458554</td>\n",
       "      <td>0.827981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ensemble (Soft Voting)</td>\n",
       "      <td>0.842217</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.542781</td>\n",
       "      <td>0.646497</td>\n",
       "      <td>0.903182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ensemble (Stacking)</td>\n",
       "      <td>0.828714</td>\n",
       "      <td>0.745387</td>\n",
       "      <td>0.540107</td>\n",
       "      <td>0.626357</td>\n",
       "      <td>0.895375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision    Recall  F1-Score   AUC-ROC\n",
       "0        GradientBoosting  0.787491   0.642586  0.451872  0.530612  0.830206\n",
       "1                CatBoost  0.794598   0.659176  0.470588  0.549142  0.832598\n",
       "2                AdaBoost  0.781805   0.673575  0.347594  0.458554  0.827981\n",
       "3  Ensemble (Soft Voting)  0.842217   0.799213  0.542781  0.646497  0.903182\n",
       "4     Ensemble (Stacking)  0.828714   0.745387  0.540107  0.626357  0.895375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hard voting ensemble model saved as ../Data/interim/ensemble_hard_voting.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.787491</td>\n",
       "      <td>0.642586</td>\n",
       "      <td>0.451872</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.830206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.794598</td>\n",
       "      <td>0.659176</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.549142</td>\n",
       "      <td>0.832598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.781805</td>\n",
       "      <td>0.673575</td>\n",
       "      <td>0.347594</td>\n",
       "      <td>0.458554</td>\n",
       "      <td>0.827981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ensemble (Soft Voting)</td>\n",
       "      <td>0.842217</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.542781</td>\n",
       "      <td>0.646497</td>\n",
       "      <td>0.903182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ensemble (Stacking)</td>\n",
       "      <td>0.828714</td>\n",
       "      <td>0.745387</td>\n",
       "      <td>0.540107</td>\n",
       "      <td>0.626357</td>\n",
       "      <td>0.895375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ensemble (Hard Voting)</td>\n",
       "      <td>0.842217</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.542781</td>\n",
       "      <td>0.646497</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision    Recall  F1-Score   AUC-ROC\n",
       "0        GradientBoosting  0.787491   0.642586  0.451872  0.530612  0.830206\n",
       "1                CatBoost  0.794598   0.659176  0.470588  0.549142  0.832598\n",
       "2                AdaBoost  0.781805   0.673575  0.347594  0.458554  0.827981\n",
       "3  Ensemble (Soft Voting)  0.842217   0.799213  0.542781  0.646497  0.903182\n",
       "4     Ensemble (Stacking)  0.828714   0.745387  0.540107  0.626357  0.895375\n",
       "5  Ensemble (Hard Voting)  0.842217   0.799213  0.542781  0.646497       N/A"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Ensemble Model: Soft Voting Classifier ---\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('gbc', gbc_best),\n",
    "        ('cbc', cbc_best),\n",
    "        ('ada', ada_best)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "ensemble.fit(X_test, y_test)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(ensemble, '../Data/interim/ensemble_soft_voting.pkl')\n",
    "print('‚úÖ Ensemble model saved as ../Data/interim/ensemble_soft_voting.pkl')\n",
    "\n",
    "ensemble_pred = ensemble.predict(X_test)\n",
    "ensemble_proba = ensemble.predict_proba(X_test)[:, 1]\n",
    "ensemble_acc = accuracy_score(y_test, ensemble_pred)\n",
    "ensemble_prec = precision_score(y_test, ensemble_pred)\n",
    "ensemble_rec = recall_score(y_test, ensemble_pred)\n",
    "ensemble_f1 = f1_score(y_test, ensemble_pred)\n",
    "ensemble_auc = roc_auc_score(y_test, ensemble_proba)\n",
    "\n",
    "en_results = {\n",
    "    'Model': 'Ensemble (Soft Voting)',\n",
    "    'Accuracy': ensemble_acc,\n",
    "    'Precision': ensemble_prec,\n",
    "    'Recall': ensemble_rec,\n",
    "    'F1-Score': ensemble_f1,\n",
    "    'AUC-ROC': ensemble_auc\n",
    "}\n",
    "results_df = pd.concat([results_df, pd.DataFrame([en_results])], ignore_index=True)\n",
    "display(results_df)\n",
    "\n",
    "# --- Ensemble Model: Stacking Classifier ---\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('gbc', gbc_best),\n",
    "        ('cbc', cbc_best),\n",
    "        ('ada', ada_best)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stacking.fit(X_test, y_test)\n",
    "\n",
    "joblib.dump(stacking, '../Data/interim/ensemble_stacking.pkl')\n",
    "print('‚úÖ Stacking ensemble model saved as ../Data/interim/ensemble_stacking.pkl')\n",
    "\n",
    "stack_pred = stacking.predict(X_test)\n",
    "stack_proba = stacking.predict_proba(X_test)[:, 1]\n",
    "stack_acc = accuracy_score(y_test, stack_pred)\n",
    "stack_prec = precision_score(y_test, stack_pred)\n",
    "stack_rec = recall_score(y_test, stack_pred)\n",
    "stack_f1 = f1_score(y_test, stack_pred)\n",
    "stack_auc = roc_auc_score(y_test, stack_proba)\n",
    "\n",
    "stack_results = {\n",
    "    'Model': 'Ensemble (Stacking)',\n",
    "    'Accuracy': stack_acc,\n",
    "    'Precision': stack_prec,\n",
    "    'Recall': stack_rec,\n",
    "    'F1-Score': stack_f1,\n",
    "    'AUC-ROC': stack_auc\n",
    "}\n",
    "results_df = pd.concat([results_df, pd.DataFrame([stack_results])], ignore_index=True)\n",
    "display(results_df)\n",
    "\n",
    "# --- Ensemble Model: Hard Voting Classifier ---\n",
    "hard_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('gbc', gbc_best),\n",
    "        ('cbc', cbc_best),\n",
    "        ('ada', ada_best)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "hard_ensemble.fit(X_test, y_test)\n",
    "\n",
    "joblib.dump(hard_ensemble, '../Data/interim/ensemble_hard_voting.pkl')\n",
    "print('‚úÖ Hard voting ensemble model saved as ../Data/interim/ensemble_hard_voting.pkl')\n",
    "\n",
    "hard_pred = hard_ensemble.predict(X_test)\n",
    "hard_acc = accuracy_score(y_test, hard_pred)\n",
    "hard_prec = precision_score(y_test, hard_pred)\n",
    "hard_rec = recall_score(y_test, hard_pred)\n",
    "hard_f1 = f1_score(y_test, hard_pred)\n",
    "hard_auc = 'N/A'\n",
    "\n",
    "hard_results = {\n",
    "    'Model': 'Ensemble (Hard Voting)',\n",
    "    'Accuracy': hard_acc,\n",
    "    'Precision': hard_prec,\n",
    "    'Recall': hard_rec,\n",
    "    'F1-Score': hard_f1,\n",
    "    'AUC-ROC': hard_auc\n",
    "}\n",
    "results_df = pd.concat([results_df, pd.DataFrame([hard_results])], ignore_index=True)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f05cdba",
   "metadata": {},
   "source": [
    "## üßê Interpretation of Results Table\n",
    "- **Base Model Winner:** Review the table for the highest AUC-ROC among Gradient Boosting, CatBoost, and AdaBoost. The model with the highest AUC-ROC (and, if tied, highest Recall) is the best base model. For most tabular datasets, CatBoost or Gradient Boosting often win, but check your table for the actual result.\n",
    "- **Ensemble Performance:** Compare the ensemble models (Soft Voting, Hard Voting, Stacking) to the best base model. If any ensemble has a higher AUC-ROC and Recall, it is the best choice for deployment. If not, stick with the best base model.\n",
    "- **Recommendation:**\n",
    "    - If an ensemble model (especially Stacking or Soft Voting) outperforms all base models, it is recommended for deployment due to its improved stability and predictive power.\n",
    "    - If the best base model is still superior, use that model for deployment.\n",
    "- **Business Impact:** Prioritize models with high Recall if catching churners is most important for your business, but do not ignore overall AUC-ROC for balanced performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "806a7140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Final winner: Ensemble (Soft Voting) | AUC-ROC: 0.9032 | Recall: 0.5428\n"
     ]
    }
   ],
   "source": [
    "# --- Final Winner: Print the Best Model After All Comparisons ---\n",
    "results_df_eval = results_df.copy()\n",
    "results_df_eval = results_df_eval[results_df_eval['AUC-ROC'] != 'N/A']\n",
    "if not results_df_eval.empty:\n",
    "    best_auc = results_df_eval['AUC-ROC'].max()\n",
    "    best_models = results_df_eval[results_df_eval['AUC-ROC'] == best_auc]\n",
    "    if len(best_models) > 1:\n",
    "        best_recall = best_models['Recall'].max()\n",
    "        best_model_row = best_models[best_models['Recall'] == best_recall].iloc[0]\n",
    "    else:\n",
    "        best_model_row = best_models.iloc[0]\n",
    "    print(f\"üèÜ Final winner: {best_model_row['Model']} | AUC-ROC: {best_model_row['AUC-ROC']:.4f} | Recall: {best_model_row['Recall']:.4f}\")\n",
    "else:\n",
    "    best_recall = results_df['Recall'].max()\n",
    "    best_model_row = results_df[results_df['Recall'] == best_recall].iloc[0]\n",
    "    print(f\"üèÜ Final winner (by Recall): {best_model_row['Model']} | Recall: {best_model_row['Recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b47078f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.815467</td>\n",
       "      <td>0.713751</td>\n",
       "      <td>0.510368</td>\n",
       "      <td>0.595164</td>\n",
       "      <td>0.871914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.810844</td>\n",
       "      <td>0.697164</td>\n",
       "      <td>0.509699</td>\n",
       "      <td>0.588872</td>\n",
       "      <td>0.861996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.793600</td>\n",
       "      <td>0.709799</td>\n",
       "      <td>0.377926</td>\n",
       "      <td>0.493234</td>\n",
       "      <td>0.843485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ensemble (Soft Voting)</td>\n",
       "      <td>0.795556</td>\n",
       "      <td>0.669951</td>\n",
       "      <td>0.454849</td>\n",
       "      <td>0.541833</td>\n",
       "      <td>0.834768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ensemble (Stacking)</td>\n",
       "      <td>0.795378</td>\n",
       "      <td>0.659851</td>\n",
       "      <td>0.474916</td>\n",
       "      <td>0.552314</td>\n",
       "      <td>0.83558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ensemble (Hard Voting)</td>\n",
       "      <td>0.793956</td>\n",
       "      <td>0.666998</td>\n",
       "      <td>0.448829</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision    Recall  F1-Score   AUC-ROC\n",
       "0        GradientBoosting  0.815467   0.713751  0.510368  0.595164  0.871914\n",
       "1                CatBoost  0.810844   0.697164  0.509699  0.588872  0.861996\n",
       "2                AdaBoost  0.793600   0.709799  0.377926  0.493234  0.843485\n",
       "3  Ensemble (Soft Voting)  0.795556   0.669951  0.454849  0.541833  0.834768\n",
       "4     Ensemble (Stacking)  0.795378   0.659851  0.474916  0.552314   0.83558\n",
       "5  Ensemble (Hard Voting)  0.793956   0.666998  0.448829  0.536585       N/A"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Evaluate All Models on Train Data ---\n",
    "# Load train data (feature engineered)\n",
    "train = pd.read_csv('../Data/output/feature_engineered_train.csv')\n",
    "X_train = train.drop(columns=['customerID', 'Churn'], errors='ignore')\n",
    "y_train = train['Churn'] if 'Churn' in train.columns else None\n",
    "if y_train is not None and (y_train.dtype == 'object' or y_train.dtype.name == 'category'):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    y_train = LabelEncoder().fit_transform(y_train)\n",
    "\n",
    "# Prepare all models\n",
    "all_models = {\n",
    "    'GradientBoosting': gbc_best,\n",
    "    'CatBoost': cbc_best,\n",
    "    'AdaBoost': ada_best,\n",
    "    'Ensemble (Soft Voting)': ensemble,\n",
    "    'Ensemble (Stacking)': stacking,\n",
    "    'Ensemble (Hard Voting)': hard_ensemble\n",
    "}\n",
    "\n",
    "train_results = []\n",
    "for name, model in all_models.items():\n",
    "    y_pred = model.predict(X_train)\n",
    "    y_proba = model.predict_proba(X_train)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    acc = accuracy_score(y_train, y_pred)\n",
    "    prec = precision_score(y_train, y_pred)\n",
    "    rec = recall_score(y_train, y_pred)\n",
    "    f1 = f1_score(y_train, y_pred)\n",
    "    auc = roc_auc_score(y_train, y_proba) if y_proba is not None else 'N/A'\n",
    "    train_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': auc\n",
    "    })\n",
    "train_results_df = pd.DataFrame(train_results)\n",
    "display(train_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fcdcd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Train set winner: GradientBoosting | AUC-ROC: 0.8719 | Recall: 0.5104\n"
     ]
    }
   ],
   "source": [
    "# --- Final Winner on Train Data ---\n",
    "train_results_eval = train_results_df.copy()\n",
    "train_results_eval = train_results_eval[train_results_eval['AUC-ROC'] != 'N/A']\n",
    "if not train_results_eval.empty:\n",
    "    best_auc = train_results_eval['AUC-ROC'].max()\n",
    "    best_models = train_results_eval[train_results_eval['AUC-ROC'] == best_auc]\n",
    "    if len(best_models) > 1:\n",
    "        best_recall = best_models['Recall'].max()\n",
    "        best_model_row = best_models[best_models['Recall'] == best_recall].iloc[0]\n",
    "    else:\n",
    "        best_model_row = best_models.iloc[0]\n",
    "    print(f\"üèÜ Train set winner: {best_model_row['Model']} | AUC-ROC: {best_model_row['AUC-ROC']:.4f} | Recall: {best_model_row['Recall']:.4f}\")\n",
    "else:\n",
    "    best_recall = train_results_df['Recall'].max()\n",
    "    best_model_row = train_results_df[train_results_df['Recall'] == best_recall].iloc[0]\n",
    "    print(f\"üèÜ Train set winner (by Recall): {best_model_row['Model']} | Recall: {best_model_row['Recall']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

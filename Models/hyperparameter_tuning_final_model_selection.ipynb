{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f076fc4c",
   "metadata": {},
   "source": [
    "# 🚀 Hyperparameter Tuning & Final Model Selection for Telco Churn Prediction\n",
    "\n",
    "This notebook performs advanced hyperparameter optimization for the top 3 baseline models and selects the best model for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9966613",
   "metadata": {},
   "source": [
    "## 📂 Load Data\n",
    "Load the feature-engineered training dataset and prepare features (X) and target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2fc61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5625, 22)\n",
      "Missing values: 0\n",
      "Features shape: (5625, 20), Target shape: (5625,)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../Data/output/feature_engineered_train.csv')\n",
    "print(f'Dataset shape: {data.shape}')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['customerID', 'Churn'])\n",
    "y = data['Churn']\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Check for missing values\n",
    "missing = data.isnull().sum().sum()\n",
    "print(f'Missing values: {missing}')\n",
    "assert missing == 0, 'There are missing values in the data!'\n",
    "print(f'Features shape: {X.shape}, Target shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f295399",
   "metadata": {},
   "source": [
    "## 🎯 Top 3 Models for Tuning\n",
    "We will tune the following models based on baseline results:\n",
    "- Gradient Boosting Classifier\n",
    "- CatBoost Classifier\n",
    "- AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e254d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (1.2.8)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: graphviz in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from catboost) (3.10.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from catboost) (2.3.1)\n",
      "Requirement already satisfied: pandas>=0.24 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from catboost) (2.3.0)\n",
      "Requirement already satisfied: scipy in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from catboost) (6.2.0)\n",
      "Requirement already satisfied: six in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.41-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting tqdm (from optuna)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.12 (from alembic>=1.5.0->optuna)\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.2.3-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from matplotlib->catboost) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from matplotlib->catboost) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in d:\\edu\\das 601 ml\\final project\\.venv\\lib\\site-packages (from plotly->catboost) (1.44.0)\n",
      "Collecting MarkupSafe>=0.9.2 (from Mako->alembic>=1.5.0->optuna)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "Downloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading greenlet-3.2.3-cp313-cp313-win_amd64.whl (297 kB)\n",
      "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, PyYAML, MarkupSafe, greenlet, colorlog, sqlalchemy, Mako, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 MarkupSafe-3.0.2 PyYAML-6.0.2 alembic-1.16.2 colorlog-6.9.0 greenlet-3.2.3 optuna-4.4.0 sqlalchemy-2.0.41 tqdm-4.67.1 typing-extensions-4.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "d:\\EDU\\DAS 601 ML\\Final Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\EDU\\DAS 601 ML\\Final Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install catboost optuna\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "import optuna\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe38ebd",
   "metadata": {},
   "source": [
    "## 🚀 Hyperparameter Search Spaces\n",
    "Defined for each model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f1c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "# CatBoost\n",
    "cb_params = {\n",
    "    'iterations': [100, 200],\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "# AdaBoost\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c55d8b",
   "metadata": {},
   "source": [
    "## 🔍 Tuning Gradient Boosting Classifier\n",
    "We use GridSearchCV and RandomizedSearchCV with 5-fold stratified CV and AUC-ROC as the main metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0052aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "GradientBoosting Best Params: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Mean/Std (AUC-ROC): 0.8411865216581503 0.008264120198961965\n",
      "Mean/Std (Accuracy): 0.7953777777777777 0.004546386436460221\n",
      "Mean/Std (Precision): 0.6627881944008334 0.008149543051864126\n",
      "Mean/Std (Recall): 0.4688963210702341 0.03360496772463002\n",
      "Training time (s): 131.3987877368927\n",
      "GradientBoosting Best Params: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Mean/Std (AUC-ROC): 0.8411865216581503 0.008264120198961965\n",
      "Mean/Std (Accuracy): 0.7953777777777777 0.004546386436460221\n",
      "Mean/Std (Precision): 0.6627881944008334 0.008149543051864126\n",
      "Mean/Std (Recall): 0.4688963210702341 0.03360496772463002\n",
      "Training time (s): 131.3987877368927\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "start = time.time()\n",
    "gbc_grid = GridSearchCV(gbc, gb_params, scoring='roc_auc', cv=cv, n_jobs=-1, verbose=1)\n",
    "gbc_grid.fit(X, y)\n",
    "grid_time = time.time() - start\n",
    "\n",
    "# RandomizedSearchCV\n",
    "start = time.time()\n",
    "gbc_rand = RandomizedSearchCV(gbc, gb_params, n_iter=10, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42, verbose=1)\n",
    "gbc_rand.fit(X, y)\n",
    "rand_time = time.time() - start\n",
    "\n",
    "# Best model\n",
    "gbc_best = gbc_grid.best_estimator_ if gbc_grid.best_score_ >= gbc_rand.best_score_ else gbc_rand.best_estimator_\n",
    "gbc_best_params = gbc_grid.best_params_ if gbc_grid.best_score_ >= gbc_rand.best_score_ else gbc_rand.best_params_\n",
    "gbc_best_time = grid_time if gbc_grid.best_score_ >= gbc_rand.best_score_ else rand_time\n",
    "\n",
    "# Cross-validated metrics\n",
    "gbc_scores = {\n",
    "    'AUC-ROC': cross_val_score(gbc_best, X, y, cv=cv, scoring='roc_auc'),\n",
    "    'Accuracy': cross_val_score(gbc_best, X, y, cv=cv, scoring='accuracy'),\n",
    "    'Precision': cross_val_score(gbc_best, X, y, cv=cv, scoring='precision'),\n",
    "    'Recall': cross_val_score(gbc_best, X, y, cv=cv, scoring='recall')\n",
    "}\n",
    "print('GradientBoosting Best Params:', gbc_best_params)\n",
    "print('Mean/Std (AUC-ROC):', gbc_scores['AUC-ROC'].mean(), gbc_scores['AUC-ROC'].std())\n",
    "print('Mean/Std (Accuracy):', gbc_scores['Accuracy'].mean(), gbc_scores['Accuracy'].std())\n",
    "print('Mean/Std (Precision):', gbc_scores['Precision'].mean(), gbc_scores['Precision'].std())\n",
    "print('Mean/Std (Recall):', gbc_scores['Recall'].mean(), gbc_scores['Recall'].std())\n",
    "print('Training time (s):', gbc_best_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c2a39",
   "metadata": {},
   "source": [
    "## 🔍 Tuning CatBoost Classifier\n",
    "We use GridSearchCV and RandomizedSearchCV with 5-fold stratified CV and AUC-ROC as the main metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714923e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "CatBoost Best Params: {'depth': 6, 'iterations': 100, 'l2_leaf_reg': 1, 'learning_rate': 0.05}\n",
      "Mean/Std (AUC-ROC): 0.8419979431033227 0.007000831926725443\n",
      "Mean/Std (Accuracy): 0.7960888888888891 0.004757009123647853\n",
      "Mean/Std (Precision): 0.6611600519127133 0.006680873340373868\n",
      "Mean/Std (Recall): 0.4775919732441472 0.03231537746938104\n",
      "Training time (s): 42.93901515007019\n",
      "CatBoost Best Params: {'depth': 6, 'iterations': 100, 'l2_leaf_reg': 1, 'learning_rate': 0.05}\n",
      "Mean/Std (AUC-ROC): 0.8419979431033227 0.007000831926725443\n",
      "Mean/Std (Accuracy): 0.7960888888888891 0.004757009123647853\n",
      "Mean/Std (Precision): 0.6611600519127133 0.006680873340373868\n",
      "Mean/Std (Recall): 0.4775919732441472 0.03231537746938104\n",
      "Training time (s): 42.93901515007019\n"
     ]
    }
   ],
   "source": [
    "cbc = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "# GridSearchCV\n",
    "start = time.time()\n",
    "cbc_grid = GridSearchCV(cbc, cb_params, scoring='roc_auc', cv=cv, n_jobs=-1, verbose=1)\n",
    "cbc_grid.fit(X, y)\n",
    "grid_time = time.time() - start\n",
    "\n",
    "# RandomizedSearchCV\n",
    "start = time.time()\n",
    "cbc_rand = RandomizedSearchCV(cbc, cb_params, n_iter=10, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42, verbose=1)\n",
    "cbc_rand.fit(X, y)\n",
    "rand_time = time.time() - start\n",
    "\n",
    "cbc_best = cbc_grid.best_estimator_ if cbc_grid.best_score_ >= cbc_rand.best_score_ else cbc_rand.best_estimator_\n",
    "cbc_best_params = cbc_grid.best_params_ if cbc_grid.best_score_ >= cbc_rand.best_score_ else cbc_rand.best_params_\n",
    "cbc_best_time = grid_time if cbc_grid.best_score_ >= cbc_rand.best_score_ else rand_time\n",
    "\n",
    "cbc_scores = {\n",
    "    'AUC-ROC': cross_val_score(cbc_best, X, y, cv=cv, scoring='roc_auc'),\n",
    "    'Accuracy': cross_val_score(cbc_best, X, y, cv=cv, scoring='accuracy'),\n",
    "    'Precision': cross_val_score(cbc_best, X, y, cv=cv, scoring='precision'),\n",
    "    'Recall': cross_val_score(cbc_best, X, y, cv=cv, scoring='recall')\n",
    "}\n",
    "print('CatBoost Best Params:', cbc_best_params)\n",
    "print('Mean/Std (AUC-ROC):', scores['AUC-ROC'].mean(), scores['AUC-ROC'].std())\n",
    "print('Mean/Std (Accuracy):', scores['Accuracy'].mean(), scores['Accuracy'].std())\n",
    "print('Mean/Std (Precision):', scores['Precision'].mean(), scores['Precision'].std())\n",
    "print('Mean/Std (Recall):', scores['Recall'].mean(), scores['Recall'].std())\n",
    "print('Training time (s):', cbc_best_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad152c1",
   "metadata": {},
   "source": [
    "## 🔍 Tuning AdaBoost Classifier\n",
    "We use GridSearchCV and RandomizedSearchCV with 5-fold stratified CV and AUC-ROC as the main metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "955464bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EDU\\DAS 601 ML\\Final Project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "AdaBoost Best Params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Mean/Std (AUC-ROC): 0.8371241507203188 0.008334270054189174\n",
      "Mean/Std (Accuracy): 0.788088888888889 0.005722125134019947\n",
      "Mean/Std (Precision): 0.6905307860047716 0.03115869602513254\n",
      "Mean/Std (Recall): 0.37257525083612036 0.04505005549293039\n",
      "Training time (s): 5.8091208934783936\n",
      "AdaBoost Best Params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Mean/Std (AUC-ROC): 0.8371241507203188 0.008334270054189174\n",
      "Mean/Std (Accuracy): 0.788088888888889 0.005722125134019947\n",
      "Mean/Std (Precision): 0.6905307860047716 0.03115869602513254\n",
      "Mean/Std (Recall): 0.37257525083612036 0.04505005549293039\n",
      "Training time (s): 5.8091208934783936\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "start = time.time()\n",
    "ada_grid = GridSearchCV(ada, ada_params, scoring='roc_auc', cv=cv, n_jobs=-1, verbose=1)\n",
    "ada_grid.fit(X, y)\n",
    "grid_time = time.time() - start\n",
    "\n",
    "# RandomizedSearchCV\n",
    "start = time.time()\n",
    "ada_rand = RandomizedSearchCV(ada, ada_params, n_iter=10, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42, verbose=1)\n",
    "ada_rand.fit(X, y)\n",
    "rand_time = time.time() - start\n",
    "\n",
    "ada_best = ada_grid.best_estimator_ if ada_grid.best_score_ >= ada_rand.best_score_ else ada_rand.best_estimator_\n",
    "ada_best_params = ada_grid.best_params_ if ada_grid.best_score_ >= ada_rand.best_score_ else ada_rand.best_params_\n",
    "ada_best_time = grid_time if ada_grid.best_score_ >= ada_rand.best_score_ else rand_time\n",
    "\n",
    "scores = {\n",
    "    'AUC-ROC': cross_val_score(ada_best, X, y, cv=cv, scoring='roc_auc'),\n",
    "    'Accuracy': cross_val_score(ada_best, X, y, cv=cv, scoring='accuracy'),\n",
    "    'Precision': cross_val_score(ada_best, X, y, cv=cv, scoring='precision'),\n",
    "    'Recall': cross_val_score(ada_best, X, y, cv=cv, scoring='recall')\n",
    "}\n",
    "print('AdaBoost Best Params:', ada_best_params)\n",
    "print('Mean/Std (AUC-ROC):', scores['AUC-ROC'].mean(), scores['AUC-ROC'].std())\n",
    "print('Mean/Std (Accuracy):', scores['Accuracy'].mean(), scores['Accuracy'].std())\n",
    "print('Mean/Std (Precision):', scores['Precision'].mean(), scores['Precision'].std())\n",
    "print('Mean/Std (Recall):', scores['Recall'].mean(), scores['Recall'].std())\n",
    "print('Training time (s):', ada_best_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116980bb",
   "metadata": {},
   "source": [
    "## 📊 Model Comparison Table\n",
    "Summarize the best results for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03755331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.788089</td>\n",
       "      <td>0.690531</td>\n",
       "      <td>0.372575</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.788089</td>\n",
       "      <td>0.690531</td>\n",
       "      <td>0.372575</td>\n",
       "      <td>{'depth': 6, 'iterations': 100, 'l2_leaf_reg':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.788089</td>\n",
       "      <td>0.690531</td>\n",
       "      <td>0.372575</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model   AUC-ROC  Accuracy  Precision    Recall  \\\n",
       "0  GradientBoosting  0.837124  0.788089   0.690531  0.372575   \n",
       "1          CatBoost  0.837124  0.788089   0.690531  0.372575   \n",
       "2          AdaBoost  0.837124  0.788089   0.690531  0.372575   \n",
       "\n",
       "                                         Best Params  \n",
       "0  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...  \n",
       "1  {'depth': 6, 'iterations': 100, 'l2_leaf_reg':...  \n",
       "2        {'learning_rate': 0.1, 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collect results\n",
    "results = [\n",
    "    {\n",
    "        'Model': 'GradientBoosting',\n",
    "        'AUC-ROC': scores['AUC-ROC'].mean(),\n",
    "        'Accuracy': scores['Accuracy'].mean(),\n",
    "        'Precision': scores['Precision'].mean(),\n",
    "        'Recall': scores['Recall'].mean(),\n",
    "        'Best Params': gbc_best_params\n",
    "    },\n",
    "    {\n",
    "        'Model': 'CatBoost',\n",
    "        'AUC-ROC': scores['AUC-ROC'].mean(),\n",
    "        'Accuracy': scores['Accuracy'].mean(),\n",
    "        'Precision': scores['Precision'].mean(),\n",
    "        'Recall': scores['Recall'].mean(),\n",
    "        'Best Params': cbc_best_params\n",
    "    },\n",
    "    {\n",
    "        'Model': 'AdaBoost',\n",
    "        'AUC-ROC': scores['AUC-ROC'].mean(),\n",
    "        'Accuracy': scores['Accuracy'].mean(),\n",
    "        'Precision': scores['Precision'].mean(),\n",
    "        'Recall': scores['Recall'].mean(),\n",
    "        'Best Params': ada_best_params\n",
    "    }\n",
    "]\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb910f",
   "metadata": {},
   "source": [
    "## 🏆 Final Model Selection\n",
    "Select the best model based on AUC-ROC, efficiency, and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2440c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final model selected: CatBoost\n"
     ]
    }
   ],
   "source": [
    "# Example: Select CatBoost if it has the highest AUC-ROC\n",
    "best_model = cbc_best if results_df.loc[1, 'AUC-ROC'] == results_df['AUC-ROC'].max() else (\n",
    "    gbc_best if results_df.loc[0, 'AUC-ROC'] == results_df['AUC-ROC'].max() else ada_best\n",
    ")\n",
    "best_model_name = 'CatBoost' if best_model == cbc_best else ('GradientBoosting' if best_model == gbc_best else 'AdaBoost')\n",
    "print(f'✅ Final model selected: {best_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b37cc",
   "metadata": {},
   "source": [
    "## 📝 Model Selection Justification\n",
    "The final model is selected based on the following criteria:\n",
    "- **AUC-ROC (primary):** The model with the highest mean AUC-ROC across 5-fold CV is preferred.\n",
    "- **Computational efficiency:** Training time and resource usage are considered, especially for large datasets.\n",
    "- **Model complexity:** Simpler models are preferred if performance is similar, and interpretability/ease of tuning is considered.\n",
    "\n",
    "**Example justification:**\n",
    "CatBoost was selected as the final model because it achieved the highest AUC-ROC score among all candidates, while also offering efficient training and robust handling of categorical features. Although Gradient Boosting and AdaBoost are strong contenders, CatBoost's native support for categorical variables and ease of hyperparameter tuning make it especially suitable for this dataset. If computational efficiency or interpretability were a higher priority and performance was similar, AdaBoost or Gradient Boosting could be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "240f7d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n==================================================\n",
      "CatBoost Hyperparameter Tuning\n",
      "==================================================\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "CatBoost Best Params: {'depth': 6, 'iterations': 100, 'l2_leaf_reg': 1, 'learning_rate': 0.05}\n",
      "Mean/Std (AUC-ROC): 0.8419979431033227 0.007000831926725443\n",
      "CatBoost Best Params: {'depth': 6, 'iterations': 100, 'l2_leaf_reg': 1, 'learning_rate': 0.05}\n",
      "Mean/Std (AUC-ROC): 0.8419979431033227 0.007000831926725443\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"CatBoost Hyperparameter Tuning\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "cbc_grid = GridSearchCV(cbc, cb_params, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "start = time.time()\n",
    "cbc_grid.fit(X, y)\n",
    "grid_time = (time.time() - start) / 60\n",
    "\n",
    "cbc_rand = RandomizedSearchCV(cbc, cb_params, cv=cv, scoring='roc_auc', n_jobs=-1, \n",
    "                             verbose=1, n_iter=50, random_state=42)\n",
    "start = time.time()\n",
    "cbc_rand.fit(X, y)\n",
    "rand_time = (time.time() - start) / 60\n",
    "\n",
    "cbc_best_params = cbc_grid.best_params_ if cbc_grid.best_score_ >= cbc_rand.best_score_ else cbc_rand.best_params_\n",
    "cbc_best = CatBoostClassifier(**cbc_best_params, random_state=42, verbose=False)\n",
    "cbc_best_time = grid_time if cbc_grid.best_score_ >= cbc_rand.best_score_ else rand_time\n",
    "\n",
    "cbc_scores = {\n",
    "    'AUC-ROC': cross_val_score(cbc_best, X, y, cv=cv, scoring='roc_auc'),\n",
    "    'Accuracy': cross_val_score(cbc_best, X, y, cv=cv, scoring='accuracy'),\n",
    "    'Precision': cross_val_score(cbc_best, X, y, cv=cv, scoring='precision'),\n",
    "    'Recall': cross_val_score(cbc_best, X, y, cv=cv, scoring='recall')\n",
    "}\n",
    "print('CatBoost Best Params:', cbc_best_params)\n",
    "print('Mean/Std (AUC-ROC):', cbc_scores['AUC-ROC'].mean(), cbc_scores['AUC-ROC'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffc9d29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n==================================================\n",
      "AdaBoost Hyperparameter Tuning\n",
      "==================================================\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EDU\\DAS 601 ML\\Final Project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 9 is smaller than n_iter=50. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "AdaBoost Best Params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Mean/Std (AUC-ROC): 0.8371241507203188 0.008334270054189174\n",
      "AdaBoost Best Params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Mean/Std (AUC-ROC): 0.8371241507203188 0.008334270054189174\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"AdaBoost Hyperparameter Tuning\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "ada_grid = GridSearchCV(ada, ada_params, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "start = time.time()\n",
    "ada_grid.fit(X, y)\n",
    "grid_time = (time.time() - start) / 60\n",
    "\n",
    "ada_rand = RandomizedSearchCV(ada, ada_params, cv=cv, scoring='roc_auc', n_jobs=-1, \n",
    "                             verbose=1, n_iter=50, random_state=42)\n",
    "start = time.time()\n",
    "ada_rand.fit(X, y)\n",
    "rand_time = (time.time() - start) / 60\n",
    "\n",
    "ada_best_params = ada_grid.best_params_ if ada_grid.best_score_ >= ada_rand.best_score_ else ada_rand.best_params_\n",
    "ada_best = AdaBoostClassifier(**ada_best_params, random_state=42)\n",
    "ada_best_time = grid_time if ada_grid.best_score_ >= ada_rand.best_score_ else rand_time\n",
    "\n",
    "ada_scores = {\n",
    "    'AUC-ROC': cross_val_score(ada_best, X, y, cv=cv, scoring='roc_auc'),\n",
    "    'Accuracy': cross_val_score(ada_best, X, y, cv=cv, scoring='accuracy'),\n",
    "    'Precision': cross_val_score(ada_best, X, y, cv=cv, scoring='precision'),\n",
    "    'Recall': cross_val_score(ada_best, X, y, cv=cv, scoring='recall')\n",
    "}\n",
    "print('AdaBoost Best Params:', ada_best_params)\n",
    "print('Mean/Std (AUC-ROC):', ada_scores['AUC-ROC'].mean(), ada_scores['AUC-ROC'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cecd9231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n============================================================\n",
      "HYPERPARAMETER TUNING RESULTS COMPARISON\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Training Time (min)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.841187</td>\n",
       "      <td>0.795378</td>\n",
       "      <td>0.662788</td>\n",
       "      <td>0.468896</td>\n",
       "      <td>131.398788</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.841998</td>\n",
       "      <td>0.796089</td>\n",
       "      <td>0.661160</td>\n",
       "      <td>0.477592</td>\n",
       "      <td>0.729742</td>\n",
       "      <td>{'depth': 6, 'iterations': 100, 'l2_leaf_reg':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.788089</td>\n",
       "      <td>0.690531</td>\n",
       "      <td>0.372575</td>\n",
       "      <td>0.124253</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model   AUC-ROC  Accuracy  Precision    Recall  \\\n",
       "0  Gradient Boosting  0.841187  0.795378   0.662788  0.468896   \n",
       "1           CatBoost  0.841998  0.796089   0.661160  0.477592   \n",
       "2           AdaBoost  0.837124  0.788089   0.690531  0.372575   \n",
       "\n",
       "   Training Time (min)                                        Best Params  \n",
       "0           131.398788  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...  \n",
       "1             0.729742  {'depth': 6, 'iterations': 100, 'l2_leaf_reg':...  \n",
       "2             0.124253        {'learning_rate': 0.1, 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n🏆 Best performing model: CatBoost\n",
      "Best AUC-ROC Score: 0.8420\n",
      "\\n✅ Final model saved as '../Data/output\\final_model.pkl'\n",
      "📋 Model metadata saved as '../Data/output\\final_model_metadata.json'\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison Results\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"HYPERPARAMETER TUNING RESULTS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = [\n",
    "    {\n",
    "        'Model': 'Gradient Boosting',\n",
    "        'AUC-ROC': gbc_scores['AUC-ROC'].mean(),\n",
    "        'Accuracy': gbc_scores['Accuracy'].mean(),\n",
    "        'Precision': gbc_scores['Precision'].mean(),\n",
    "        'Recall': gbc_scores['Recall'].mean(),\n",
    "        'Training Time (min)': gbc_best_time,\n",
    "        'Best Params': gbc_best_params\n",
    "    },\n",
    "    {\n",
    "        'Model': 'CatBoost',\n",
    "        'AUC-ROC': cbc_scores['AUC-ROC'].mean(),\n",
    "        'Accuracy': cbc_scores['Accuracy'].mean(),\n",
    "        'Precision': cbc_scores['Precision'].mean(),\n",
    "        'Recall': cbc_scores['Recall'].mean(),\n",
    "        'Training Time (min)': cbc_best_time,\n",
    "        'Best Params': cbc_best_params\n",
    "    },\n",
    "    {\n",
    "        'Model': 'AdaBoost',\n",
    "        'AUC-ROC': ada_scores['AUC-ROC'].mean(),\n",
    "        'Accuracy': ada_scores['Accuracy'].mean(),\n",
    "        'Precision': ada_scores['Precision'].mean(),\n",
    "        'Recall': ada_scores['Recall'].mean(),\n",
    "        'Training Time (min)': ada_best_time,\n",
    "        'Best Params': ada_best_params\n",
    "    }\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "\n",
    "# Select best model based on AUC-ROC score\n",
    "best_model = cbc_best if results_df.loc[1, 'AUC-ROC'] == results_df['AUC-ROC'].max() else (\n",
    "    gbc_best if results_df.loc[0, 'AUC-ROC'] == results_df['AUC-ROC'].max() else ada_best\n",
    ")\n",
    "\n",
    "best_model_name = results_df.loc[results_df['AUC-ROC'].idxmax(), 'Model']\n",
    "print(f\"\\\\n🏆 Best performing model: {best_model_name}\")\n",
    "print(f\"Best AUC-ROC Score: {results_df['AUC-ROC'].max():.4f}\")\n",
    "\n",
    "# Save the final model to data output folder\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Ensure the data output directory exists\n",
    "output_dir = '../Data/output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the final model\n",
    "model_path = os.path.join(output_dir, 'final_model.pkl')\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"\\\\n✅ Final model saved as '{model_path}'\")\n",
    "\n",
    "# Also save model metadata for reference\n",
    "metadata = {\n",
    "    'model_name': best_model_name,\n",
    "    'model_type': type(best_model).__name__,\n",
    "    'best_params': results_df.loc[results_df['AUC-ROC'].idxmax(), 'Best Params'],\n",
    "    'performance_metrics': {\n",
    "        'AUC-ROC': results_df['AUC-ROC'].max(),\n",
    "        'Accuracy': results_df.loc[results_df['AUC-ROC'].idxmax(), 'Accuracy'],\n",
    "        'Precision': results_df.loc[results_df['AUC-ROC'].idxmax(), 'Precision'],\n",
    "        'Recall': results_df.loc[results_df['AUC-ROC'].idxmax(), 'Recall'],\n",
    "        'Training Time (min)': results_df.loc[results_df['AUC-ROC'].idxmax(), 'Training Time (min)']\n",
    "    },\n",
    "    'selection_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(output_dir, 'final_model_metadata.json')\n",
    "import json\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "print(f\"📋 Model metadata saved as '{metadata_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46fb944",
   "metadata": {},
   "source": [
    "## 📊 Final Model Selection\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Performance Comparison**: The hyperparameter tuning revealed distinct performance differences between the three models\n",
    "2. **Best Model**: Based on AUC-ROC score, the optimal model was automatically selected\n",
    "3. **Training Efficiency**: All models completed training within reasonable time constraints\n",
    "4. **Robustness**: Cross-validation ensured reliable performance estimates\n",
    "\n",
    "### Next Steps:\n",
    "- The selected model will be used in the final evaluation notebook\n",
    "- Further validation on the test set will confirm generalization capability\n",
    "- The tuned model is ready for deployment consideration\n",
    "\n",
    "**Note**: This corrected version uses separate score variables (`gbc_scores`, `cbc_scores`, `ada_scores`) to ensure accurate model comparison, fixing the variable overwriting issue identified in the error analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
